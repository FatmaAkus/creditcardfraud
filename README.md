In this project, we aimed to analyze financial transactions for fraud detection using several machine learning models. We performed a detailed investigation of the dataset, ensuring data quality by checking for missing values and addressing class imbalance. We also visualized key features and their relationships before proceeding to model development. The dataset was divided into three sets: train, validation, and test.
We experimented with various predictive models, starting with the RandomForestClassifier. The results showed an AUC score of 0.85 for the test set, indicating the model performed well in distinguishing fraudulent transactions from legitimate ones.
Next, we trained an AdaBoostClassifier model, which showed a slightly lower AUC score of 0.83 when predicting the target for the test set. This suggested that while AdaBoost was still a competent model, it was outperformed by RandomForestClassifier.
Following that, we employed the CatBoostClassifier, which yielded an AUC score of 0.86 after training 500 iterations. This showed a slight improvement over both RandomForest and AdaBoost.
For XGBoost, we first validated the model on the validation set. The validation score was 0.984, which demonstrated its strong ability to handle the imbalanced data. After using the best iteration model to predict the test set, we achieved an impressive AUC score of 0.974.
We then trained the LightGBM model, leveraging both train-validation split and cross-validation. For the train-validation split, the model reached an AUC score of 0.974 on the validation set and 0.946 on the test set, suggesting it was effective for predicting fraudulent transactions. Using cross-validation, the AUC score for the test set predictions was 0.93, further confirming LightGBM's strong performance.
Overall, the results indicate that XGBoost and LightGBM outperformed the other models, achieving the highest AUC scores. These models were particularly effective at detecting fraud in financial transactions, with XGBoost providing the best performance on the test set.
###Summary of AUC Scores:
RandomForestClassifier: AUC = 0.85 AdaBoostClassifier: AUC = 0.83 CatBoostClassifier: AUC = 0.86 XGBoost: Validation AUC = 0.984 Test AUC = 0.974 LightGBM: Train-Validation Split AUC = 0.974 (Validation), 0.946 (Test) Cross-Validation AUC = 0.93 (Test)
###Final Thoughts:
Based on these results, XGBoost and LightGBM are the most effective models for fraud detection in this dataset. Fine-tuning these models or using ensemble techniques could further improve the performance.
